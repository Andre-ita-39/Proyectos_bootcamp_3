{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5eb92ee-0223-4839-8258-056c48061fa0",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Función Encapsulada</span>\n",
    "\n",
    "**La función desarrollada en el punto 6 tiene como objetivo encapsular todos los pasos necesarios para transformar y limpiar los datasets originales, de manera que estén listos para ser utilizados en análisis posteriores o modelado predictivo.** \n",
    "\n",
    "**Este enfoque permite:**\n",
    "\n",
    "- **Reutilización:** Al separar la lógica de limpieza en un módulo independiente, podemos importarla y aplicar las transformaciones sin duplicar lo ya realizado.\n",
    "- **Estandarización:** Garantizamos que todos los datasets procesados sigan las mismas reglas de limpieza y transformación, lo que elimina inconsistencias y facilita la comparación entre diferentes datasets.\n",
    "- **Optimización del Tiempo:** Al trabajar con datasets ya procesados, evitamos realizar tareas de limpieza repetitivas, mejorando la eficiencia en el desarrollo del proyecto.\n",
    "  \n",
    "**¿Por Qué Presentarla como Módulo?**\n",
    "\n",
    "- Este diseño modular es una práctica común en proyectos de análisis y desarrollo de modelos, ya que:\n",
    "\n",
    "    - **Aumenta la claridad del código:** Separar las transformaciones en un archivo dedicado ayuda a mantener el código principal más limpio y fácil de entender.\n",
    "    - **Facilita la colaboración:** Otros miembros del equipo pueden usar o mejorar la función sin afectar el resto del proyecto.\n",
    "    - **Evita errores:** Trabajar directamente con datasets ya limpios reduce la probabilidad de cometer errores en transformaciones repetidas.\n",
    "\n",
    "---\n",
    "\n",
    "**<span style=\"color:olive\">Descripción de la Función</span>**\n",
    "\n",
    "La **función procesar_dataset** realiza las siguientes operaciones clave:\n",
    "\n",
    "1. **Creación de Variables Derivadas:**\n",
    "\n",
    "    - Variables basadas en fechas, como is_weekend, is_holiday, y is_high_season, que capturan patrones estacionales y de comportamiento.\n",
    "    - Conversión de stop a una métrica numérica (stop_numeric).\n",
    "    - Cálculo de distancias entre ciudades (distance).\n",
    "\n",
    "2. **Validación de Datos:**\n",
    "\n",
    "    - Elimina columnas redundantes, como time_taken si ya existe time_in_minutes.\n",
    "    - Marca valores atípicos (is_outlier), útiles para análisis exploratorios y modelado.\n",
    "\n",
    "3. **Codificación de Variables Categóricas:** Transforma columnas como day_of_week en variables numéricas mediante codificación one-hot.\n",
    "\n",
    "4. **Preparación para el Modelado:** Devuelve un dataset listo para ser utilizado en modelos predictivos o análisis adicionales.\n",
    "\n",
    "---\n",
    "\n",
    "**Importación en el Proyecto**\n",
    "\n",
    "Al colocar la función en un archivo separado,**Función Encapsulada Punto 6_Prueba.ipynb**, podemos integrarla fácilmente en otros scripts o notebooks del proyecto. \n",
    "\n",
    "**<span style=\"color:green\">import import_ipynb</span>**\n",
    "\n",
    "**<span style=\"color:green\">from Funcion_Encapsulada_Punto_6_Prueba import procesar_dataset</span>**\n",
    "\n",
    "---\n",
    "\n",
    "- El motivo de presentar esta función como un módulo independiente es demostrar una práctica profesional en el manejo de proyectos de análisis de datos. \n",
    "\n",
    "- Esto incluye:\n",
    "\n",
    "    - **Modularidad:** Dividir el proyecto en componentes manejables y reutilizables.\n",
    "    - **Escalabilidad:** Facilitar la extensión del proyecto en el futuro, permitiendo agregar nuevas transformaciones sin afectar el flujo existente.\n",
    "    - **Mantenimiento:** Mejorar la capacidad de depuración y actualización del código.\n",
    "\n",
    "**Esta estrategia refleja un enfoque ordenado, eficiente y profesional en el desarrollo de proyectos de análisis y modelado de datos, alineado con estándares de la industria.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8bcd9-cd17-4678-98d6-fe7351d8624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_dataset(df, dataset_name):\n",
    "    \"\"\"\n",
    "    Procesa un dataset original y devuelve un dataset limpio y procesado.\n",
    "    \n",
    "    Incluye:\n",
    "    - Transformaciones y variables adicionales (basadas en el punto 5).\n",
    "    - Limpieza de datos.\n",
    "    - Validación de redundancias y eliminación de columnas innecesarias.\n",
    "    - Codificación de variables categóricas.\n",
    "\n",
    "    Parámetros:\n",
    "        df (DataFrame): Dataset original a procesar.\n",
    "        dataset_name (str): Nombre del dataset (por ejemplo, 'Business' o 'Economy').\n",
    "\n",
    "    Retorna:\n",
    "        DataFrame limpio y procesado.\n",
    "    \"\"\"\n",
    "    # Crear una copia del DataFrame original\n",
    "    df = df.copy()\n",
    "\n",
    "    # ----------------------\n",
    "    # Identificar el dataset\n",
    "    # ----------------------\n",
    "    df['dataset_name'] = dataset_name\n",
    "\n",
    "    # ----------------------\n",
    "    # 1. Variables basadas en 'date'\n",
    "    # ----------------------\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['is_weekend'] = df['date'].dt.dayofweek >= 5\n",
    "    holidays = pd.to_datetime([\"2022-01-01\", \"2022-12-25\", \"2022-07-04\", \"2022-11-24\"])\n",
    "    df['is_holiday'] = df['date'].isin(holidays)\n",
    "    high_season_months = [12, 1, 7]\n",
    "    df['is_high_season'] = df['date'].dt.month.isin(high_season_months)\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "\n",
    "    # ----------------------\n",
    "    # 2. Incorporar distancia entre ciudades\n",
    "    # ----------------------\n",
    "    distances = {\n",
    "        (\"Delhi\", \"Mumbai\"): 1400,\n",
    "        (\"Delhi\", \"Bangalore\"): 2100,\n",
    "    }\n",
    "    df['distance'] = df.apply(\n",
    "        lambda row: distances.get((row['from'], row['to']), np.nan), axis=1\n",
    "    )\n",
    "\n",
    "    # ----------------------\n",
    "    # 3. Validar duplicidad o redundancia\n",
    "    # ----------------------\n",
    "    if 'time_taken' in df.columns and 'time_in_minutes' in df.columns:\n",
    "        df = df.drop(columns=['time_taken'])\n",
    "\n",
    "    # ----------------------\n",
    "    # 4. Validar y procesar 'is_outlier'\n",
    "    # ----------------------\n",
    "    if 'is_outlier' in df.columns:\n",
    "        print(f\"Outliers marcados en el dataset {dataset_name}: {df['is_outlier'].sum()}\")\n",
    "\n",
    "    # ----------------------\n",
    "    # 5. Codificación de nuevas variables categóricas\n",
    "    # ----------------------\n",
    "    df = pd.get_dummies(df, columns=['day_of_week'], drop_first=True)\n",
    "    for col in ['is_weekend', 'is_holiday', 'is_high_season']:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "    # ----------------------\n",
    "    # 6. Limpieza y ajustes finales\n",
    "    # ----------------------\n",
    "    # Convertir 'stop' a una métrica numérica\n",
    "    if 'stop' in df.columns:\n",
    "        df['stop_numeric'] = df['stop'].apply(\n",
    "            lambda x: 0 if 'non-stop' in x else int(x.split()[0]) if isinstance(x, str) else np.nan\n",
    "        )\n",
    "\n",
    "    # Manejar valores nulos en las nuevas columnas\n",
    "    df.fillna({'distance': 0, 'stop_numeric': 0}, inplace=True)\n",
    "\n",
    "    # ----------------------\n",
    "    # Retornar el DataFrame limpio y procesado\n",
    "    # ----------------------\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
